import os
import google.generativeai as genai
from dotenv import load_dotenv

load_dotenv()

class Brain:
    def __init__(self):
        # R√©cup√©ration de la cl√© API
        # On cherche GEMINI_API_KEY ou GOOGLE_API_KEY
        keys_str = os.getenv("GEMINI_API_KEY")
        
        if not keys_str:
            print("üî¥ ERREUR : Pas de cl√© API trouv√©e dans .env")
            self.api_keys = []
        else:
            self.api_keys = [k.strip() for k in keys_str.split(',')]
            
        self.current_key_index = 0
        self.history = [] 
        
        # Instruction de base
        self.persona_instruction = "Tu es un assistant utile."
        self.model = None
        self.chat = None
        
        # On utilise FLASH 1.5 : C'est le meilleur compromis Vitesse/Prix/Multimodal
        self.model_name = "gemini-2.5-flash"
        
        self.init_model()

    def update_persona(self, name, scenario, behavior):
        """Met √† jour l'identit√© de l'IA"""
        self.persona_instruction = f"""
        Tu incarnes {name}.
        SC√âNARIO : {scenario}
        COMPORTEMENT : {behavior}
        
        R√àGLES IMPORTANTES :
        - Tu es dans une conversation ORALE.
        - Ne fais JAMAIS de listes √† puces ou de formatage complexe (gras, italique).
        - Fais des phrases courtes, claires et percutantes.
        - R√©agis directement √† ce qu'on te dit (ou au ton de la voix).
        """
        print(f"üß† Persona mise √† jour : {name}")
        self.history = [] 
        self.init_model()

    def init_model(self):
        if not self.api_keys: return

        genai.configure(api_key=self.api_keys[self.current_key_index])
        try:
            self.model = genai.GenerativeModel(
                model_name=self.model_name, 
                system_instruction=self.persona_instruction
            )
            # On garde un historique vide au d√©but
            self.chat = self.model.start_chat(history=[])
            print(f"üß† Cerveau pr√™t : {self.model_name}")
        except Exception as e:
            print(f"üî¥ Erreur chargement mod√®le : {e}")

    def think_from_audio(self, audio_path):
        """
        Re√ßoit un chemin de fichier audio (mp3/wav/webm),
        L'envoie √† Gemini pour qu'il l'√©coute,
        Et retourne la r√©ponse textuelle.
        """
        try:
            print(f"üëÇ Brain √©coute le fichier : {audio_path}")
            
            # 1. Upload du fichier vers les serveurs Google (c'est tr√®s rapide)
            # Note: Le mime_type peut √™tre 'audio/mp3', 'audio/wav', 'audio/webm'
            audio_file = genai.upload_file(path=audio_path)
            
            # 2. G√©n√©ration de la r√©ponse
            # On envoie le fichier audio + le prompt syst√®me implicite (d√©fini dans init_model)
            response = self.model.generate_content([
                "√âcoute cet audio attentivement et r√©ponds-moi en suivant ton persona.", 
                audio_file
            ])
            
            # 3. Nettoyage (Bonne pratique : on ne garde pas les fichiers chez Google)
            # (Optionnel, Google les supprime auto apr√®s 48h, mais on peut le faire ici)
            # genai.delete_file(audio_file.name)
            
            print(f"üß† R√©ponse g√©n√©r√©e : {response.text[:50]}...")
            return response.text

        except Exception as e:
            print(f"üî¥ Erreur Brain Audio : {e}")
            return "D√©sol√©, je n'ai pas bien entendu. Peux-tu r√©p√©ter ?"
         
    def think_streaming(self, user_text):
        if not self.chat: return
        try:
            response = self.chat.send_message(user_text, stream=True)
            buffer = ""
            for chunk in response:
                text = chunk.text
                buffer += text
                if any(p in text for p in [".", "?", "!", "\n"]):
                    if len(buffer) > 5:
                        yield buffer
                        buffer = ""
            if buffer: yield buffer
        except Exception as e:
            yield "D√©sol√©, j'ai un petit bug de cerveau."
            print(f"üî¥ Erreur Chat : {e}")


    def analyze_pitch(self, prompt_context):
        """Analyse le pitch selon la m√©thode QQOQCP + Structure Id√©ale"""
        print(f"üìä Envoi √† {self.model_name} pour analyse structur√©e...")
        
        analysis_prompt = f"""
        Tu es un expert en Pitch de Startup (Type Y-Combinator).
        Analyse ce pitch en v√©rifiant la pr√©sence des 9 points cl√©s de la structure id√©ale :
        
        1. POURQUOI (Le probl√®me/Accroche)
        2. QUOI (La solution)
        3. QUI (La cible)
        4. COMMENT (Le fonctionnement)
        5. O√ô/QUAND (Contexte/March√©)
        6. POURQUOI TOI (Diff√©renciation)
        7. ARGENT (Mod√®le √©co - Optionnel mais bon √† savoir)
        8. APPEL √Ä L'ACTION (Ce que tu veux)
        
        CONTEXTE ET STATS DU PITCHEUR :
        {prompt_context}
        
        CONSIGNES DE R√âPONSE (JSON STRICT) :
        Tu dois noter S√âV√àREMENT. Si un point cl√© est absent, dis-le.
        
        R√©ponds UNIQUEMENT avec ce JSON :
        {{
            "note": "Note/100",
            "accroche_probleme": "Analyse du WHY et du probl√®me (1 phrase)",
            "solution_cible": "Analyse du QUOI et QUI (1 phrase)",
            "unicite_business": "Analyse du POURQUOI TOI et du MOD√àLE √âCO (1 phrase)",
            "cta_action": "Analyse de l'APPEL √Ä L'ACTION (1 phrase)",
            "elements_manquants": "Liste les points oubli√©s parmi les 9 (ex: 'Manque le Business Model, Manque le CTA...')",
            "conseil": "Le conseil prioritaire pour am√©liorer la structure"
        }}
        """
        
        try:
            response = self.model.generate_content(analysis_prompt)
            clean_json = response.text.replace("```json", "").replace("```", "").strip()
            return clean_json
        except Exception as e:
            print(f"üî¥ CRASH ANALYSE : {e}")
            return '{"note": "0", "accroche_probleme": "Erreur", "solution_cible": "Erreur", "unicite_business": "Erreur", "cta_action": "Erreur", "elements_manquants": "Erreur", "conseil": "Erreur technique"}'